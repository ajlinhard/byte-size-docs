# Databricks Certifications
At the time of making this page Databricks did not have the free classes they offer well organized into groups for the certifications they offer. To avoid the fee of the expert led classes I have the videos organized below. These classes are helpful, but the more background in Spark, SQL, and Data Engineering the easier studying for these exams will be. 
<br>**Recertification:** Recertification is required every two years to maintain your certified status

Related Certifications:
- [AWS Cloud Certs for Data Engineers](https://github.com/ajlinhard/byte-size-docs/blob/main/AWS/AWS-Certifications.md)
= [Snowflake Certs](https://github.com/ajlinhard/byte-size-docs/blob/main/Snowflake/Snowflake-Certifications.md)

## Table of Contents:
- [Apache Spark Course](https://www.databricks.com/training/catalog?roles=apache-spark-developer)
- [Databricks Certified Data Engineer Associate](#Databricks-Certified-Data-Engineer-Associate)
- [Databricks Certified Data Engineer Professional](#Databricks-Certified-Data-Engineer-Professional)
- [Summary & Recommendations](#Summary-&-Recommendations)

## **Databricks Certified Data Engineer Associate**
This certification assesses the ability to use the Databricks Lakehouse Platform to complete introductory data engineering tasks, including understanding the platform's workspace, architecture, and capabilities. It evaluates skills in performing multi-hop architecture ETL tasks using Apache Spark SQL and Python in both batch and incrementally processed paradigms.
<br>**[PDF of Certification Details](https://github.com/ajlinhard/byte-size-docs/blob/main/Databricks/docs/databricks-certified-data-engineer-associate-exam-guide-1-mar-2025.pdf)**

**Topics & Tools Covered:**
- **Core Platform Knowledge:** Understanding of the Lakehouse Platform and its workspace, its architecture, and its capabilities
- **Data Processing:** Apache Spark SQL and Python for ETL pipelines
- **Delta Lake:** Table management, manipulation, and optimizations
- **Multi-hop Architecture:** Building production-ready ETL pipelines
- **Databricks SQL:** Queries and dashboards in production
- **Security:** Entity permissions and access control

**Prerequisites:** 6+ months of hands-on experience performing the data engineering tasks outlined in the exam guide

### Courses:
○ [Data Ingestion with Delta Lake](https://customer-academy.databricks.com/learn/courses/2963/data-ingestion-with-delta-lake/lessons)
○ [Deploy Workloads with Databricks Workflows](https://customer-academy.databricks.com/learn/courses/1365/deploy-workloads-with-databricks-workflows)
○ [Build Data Pipelines with Delta Live Tables](https://customer-academy.databricks.com/learn/courses/2971/build-data-pipelines-with-delta-live-tables/lessons)
○ [Data Management and Governance with Unity Catalog](https://customer-academy.databricks.com/learn/courses/3144/data-management-and-governance-with-unity-catalog)

## **Databricks Certified Data Engineer Professional**
This certification assesses an individual's ability to use Databricks to perform advanced data engineering tasks, including understanding of the Databricks platform and developer tools like Apache Spark, Delta Lake, MLflow, and the Databricks CLI and REST API.
<br>**[PDF of Certification Details](https://github.com/ajlinhard/byte-size-docs/blob/main/Databricks/docs/databricks-certified-data-engineer-professional-exam-guide-1-mar-2025.pdf)**

**Topics & Tools Covered:**
- **Advanced Platform Tools:** Apache Spark™, Delta Lake, MLflow, and the Databricks CLI and REST API
- **Pipeline Optimization:** Building optimized and cleaned ETL pipelines
- **Data Modeling:** Ability to model data into a lakehouse using knowledge of general data modeling concepts
- **Production Best Practices:** Ensuring that data pipelines are secure, reliable, monitored and tested before deployment
- **Programming Languages:** Code examples in this exam will primarily be in Python. However, any and all references to Delta Lake functionality will be made in SQL

**Prerequisites:** 1+ years of hands-on experience performing the data engineering tasks outlined in the exam guide

### Courses:
○ [Databricks Streaming and Delta Live Tables - Delta Dawn](https://www.databricks.com/training/catalog/databricks-streaming-and-delta-live-tables-2972)
○ [Databricks Data Privacy](https://customer-academy.databricks.com/learn/courses/3767/databricks-data-privacy)
○ [Databricks Performance Optimization Delta Dawn](https://customer-academy.databricks.com/learn/courses/2967/databricks-performance-optimization/lessons)
○ [Automated Testing and Deployment with Databricks Asset Bundle](https://customer-academy.databricks.com/learn/courses/3489/automated-deployment-with-databricks-asset-bundles)
Not Officially Recommended
○ [Building Data Pipelines with Delta Live Tables](https://customer-academy.databricks.com/learn/courses/2971/build-data-pipelines-with-delta-live-tables/lessons)
○ [DevOps Essentials for Data Engineers](https://www.databricks.com/training/catalog/devops-essentials-for-data-engineering-3640)

### Extra Courses:
- [Data Ingestion with Delta Lake](https://customer-academy.databricks.com/learn/courses/2963/data-ingestion-with-delta-lake/lessons/)
- [Data Preparations for Machnine Learning](https://customer-academy.databricks.com/learn/courses/2343/data-preparation-for-machine-learning)
- [Advance Machine Learning Operations](https://customer-academy.databricks.com/learn/courses/3508/advanced-machine-learning-operations)
- [Create Your First Databrick Express Workspace](https://customer-academy.databricks.com/learn/courses/3697/create-your-first-workspace-using-databricks-express)
- [Automate Production Workdlows](https://customer-academy.databricks.com/learn/courses/2143/automate-production-workflows)
- [AWS Platform Architect - Learning Plan](https://customer-academy.databricks.com/learn/learning-plans/262/aws-databricks-platform-architect-learning-plan-public)

---
## **Summary & Recommendations**

**For Beginners:**
- Start with **Databricks Associate** (6+ months experience) or **SnowPro Core** 
- AWS requires more experience (2-3 years) for their Data Engineer certification

**For Experienced Engineers:**
- **Databricks Professional** for advanced lakehouse architecture
- **Snowflake Advanced Data Engineer** for cloud data warehousing expertise
- **AWS Data Engineer Associate** for comprehensive cloud data engineering skills

Each certification focuses on different aspects of the modern data stack, with Databricks emphasizing lakehouse architecture and ML integration, Snowflake focusing on cloud data warehousing and sharing, and AWS covering the full spectrum of cloud-native data engineering services.
